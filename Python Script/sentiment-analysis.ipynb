{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "This code for the fine-tuning process of XLNet for sentiment analysis is based on the following example, published on Medium: <br>\n",
    "\n",
    "link to article: https://medium.com/swlh/using-xlnet-for-sentiment-classification-cfa948e65e85 <br>\n",
    "author: Shanay Ghag <br>\n",
    "published at: Jun 16, 2020 <br>\n",
    "link to GitHub: https://github.com/shanayghag/Sentiment-classification-using-XLNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import sentencepiece\n",
    "from transformers import XLNetForSequenceClassification\n",
    "from transformers import XLNetTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for text preprocessing \n",
    "def prepare_text(text):\n",
    "    text = re.sub(r\"@[A-Za-z0-9_]+\", ' ', text) # remove @user \n",
    "    text = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', text) # remove links\n",
    "    text = re.sub(r\"[^a-zA-z.!?'0-9]\", ' ', text) # remove smileys\n",
    "    text = re.sub('[^A-Za-z0-9]+', ' ', text) # remove any other special characters\n",
    "    text = re.sub('#', '', text) # remove hash sign\n",
    "    text = re.sub('\\t', ' ',  text) # remove tab\n",
    "    text = re.sub(r\" +\", ' ', text) # remove multiple whitespaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for sentiment prediction\n",
    "def predict_sentiment(text):\n",
    "    review_text = text\n",
    "    \n",
    "    df = pd.DataFrame(columns=['positive_score', 'negative_score', 'text', 'sentiment'])\n",
    "\n",
    "    encoded_review = tokenizer.encode_plus(review_text,\n",
    "                                           max_length=MAX_LEN,\n",
    "                                           truncation=True,\n",
    "                                           add_special_tokens=True,\n",
    "                                           return_token_type_ids=False,\n",
    "                                           pad_to_max_length=False,\n",
    "                                           return_attention_mask=True,\n",
    "                                           return_tensors='pt',)\n",
    "\n",
    "    input_ids = pad_sequences(encoded_review['input_ids'],\n",
    "                              maxlen=MAX_LEN, \n",
    "                              dtype=torch.Tensor ,\n",
    "                              truncating=\"post\",\n",
    "                              padding=\"post\")\n",
    "    input_ids = input_ids.astype(dtype = 'int64')\n",
    "    input_ids = torch.tensor(input_ids) \n",
    "\n",
    "    attention_mask = pad_sequences(encoded_review['attention_mask'], \n",
    "                                   maxlen=MAX_LEN, dtype=torch.Tensor ,\n",
    "                                   truncating=\"post\",\n",
    "                                   padding=\"post\")\n",
    "    attention_mask = attention_mask.astype(dtype = 'int64')\n",
    "    attention_mask = torch.tensor(attention_mask) \n",
    "\n",
    "    input_ids = input_ids.reshape(1,512).to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    outputs = outputs[0][0].cpu().detach()\n",
    "\n",
    "    probs = F.softmax(outputs, dim=-1).cpu().detach().numpy().tolist()\n",
    "    _, prediction = torch.max(outputs, dim =-1)\n",
    "\n",
    "    result = {'positive_score': probs[1], 'negative_score': probs[0], 'text': review_text, 'sentiment': class_names[prediction]}\n",
    "    df = df.append(result, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset with all tweets:\n",
    "dtype={'text': str, 'id': str, 'tweet_id': str, 'title': str, 'outlet': str, 'twitter_handle': str, 'article_url': str, 'adfontes_url': str, 'bias_score': float, 'reliability_score': float}\n",
    "\n",
    "# note: this scrip was implemented using Kaggle's GPU. The dataset 'all_tweets_final' was loaded into the Kaggle repo and accessed from there\n",
    "all_tweets = pd.read_csv('../input/all-tweets-final/all_tweets_final.csv', dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply text preprocessing to tweets:\n",
    "all_tweets['text_prepared'] = all_tweets['text'].apply(prepare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load XLNet & Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read classifier:\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels = 2)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('../input/new-sentiment-model/xlnet_model_sentiment.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "MAX_LEN = 512\n",
    "class_names = ['negative', 'positive'] # 0=negative; 1=positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run for all Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = all_tweets['text_prepared'].tolist() # 175807 comments\n",
    "results = pd.DataFrame()\n",
    "\n",
    "for tweet in tweets:\n",
    "    results = results.append(predict_sentiment(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add tweet id\n",
    "results.insert(loc=0, column=\"id\", value=all_tweets['id'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: this scrip was implemented using Kaggle's GPU. The classified sentiment dataset was saved into the Kaggle repo and downloaded manually\n",
    "results.to_csv('all_tweets_sentiment.csv', header=True, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
