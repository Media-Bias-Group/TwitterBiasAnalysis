{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "This code for the fine-tuning process of XLNet for hate speech detection is based on the following example, published on Medium: <br>\n",
    "\n",
    "link to article: https://medium.com/swlh/using-xlnet-for-sentiment-classification-cfa948e65e85 <br>\n",
    "author: Shanay Ghag <br>\n",
    "published at: Jun 16, 2020 <br>\n",
    "link to GitHub: https://github.com/shanayghag/Sentiment-classification-using-XLNet <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import sentencepiece\n",
    "from transformers import XLNetForSequenceClassification\n",
    "from transformers import XLNetTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-04T14:02:35.693726Z",
     "iopub.status.busy": "2022-03-04T14:02:35.693012Z",
     "iopub.status.idle": "2022-03-04T14:02:35.702Z",
     "shell.execute_reply": "2022-03-04T14:02:35.700975Z",
     "shell.execute_reply.started": "2022-03-04T14:02:35.693681Z"
    }
   },
   "outputs": [],
   "source": [
    "# define function for text preprocessing \n",
    "def prepare_text(text):\n",
    "    text = re.sub(r\"@[A-Za-z0-9_]+\", ' ', text) # remove @user \n",
    "    text = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', text) # remove links\n",
    "    text = re.sub(r\"[^a-zA-z.!?'0-9]\", ' ', text) # remove smileys\n",
    "    text = re.sub('[^A-Za-z0-9]+', ' ', text) # remove any other special characters\n",
    "    text = re.sub('#', '', text) # remove hash sign\n",
    "    text = re.sub('\\t', ' ',  text) # remove tab\n",
    "    text = re.sub(r\" +\", ' ', text) # remove multiple whitespaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-04T14:02:36.645388Z",
     "iopub.status.busy": "2022-03-04T14:02:36.645073Z",
     "iopub.status.idle": "2022-03-04T14:02:36.658171Z",
     "shell.execute_reply": "2022-03-04T14:02:36.657256Z",
     "shell.execute_reply.started": "2022-03-04T14:02:36.645353Z"
    }
   },
   "outputs": [],
   "source": [
    "# define function for sentiment prediction\n",
    "def predict_hate(text):\n",
    "    review_text = text\n",
    "    \n",
    "    df = pd.DataFrame(columns=['positive_score', 'negative_score', 'text', 'hate_value'])\n",
    "\n",
    "    encoded_review = tokenizer.encode_plus(review_text,\n",
    "                                           max_length=MAX_LEN,\n",
    "                                           truncation=True,\n",
    "                                           add_special_tokens=True,\n",
    "                                           return_token_type_ids=False,\n",
    "                                           pad_to_max_length=False,\n",
    "                                           return_attention_mask=True,\n",
    "                                           return_tensors='pt',)\n",
    "\n",
    "    input_ids = pad_sequences(encoded_review['input_ids'],\n",
    "                              maxlen=MAX_LEN, \n",
    "                              dtype=torch.Tensor ,\n",
    "                              truncating=\"post\",\n",
    "                              padding=\"post\")\n",
    "    input_ids = input_ids.astype(dtype = 'int64')\n",
    "    input_ids = torch.tensor(input_ids) \n",
    "\n",
    "    attention_mask = pad_sequences(encoded_review['attention_mask'], \n",
    "                                   maxlen=MAX_LEN, dtype=torch.Tensor ,\n",
    "                                   truncating=\"post\",\n",
    "                                   padding=\"post\")\n",
    "    attention_mask = attention_mask.astype(dtype = 'int64')\n",
    "    attention_mask = torch.tensor(attention_mask) \n",
    "\n",
    "    input_ids = input_ids.reshape(1,512).to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    outputs = outputs[0][0].cpu().detach()\n",
    "\n",
    "    probs = F.softmax(outputs, dim=-1).cpu().detach().numpy().tolist()\n",
    "    _, prediction = torch.max(outputs, dim =-1)\n",
    "\n",
    "    result = {'positive_score': probs[1], 'negative_score': probs[0], 'text': review_text, 'hate_value': class_names[prediction]}\n",
    "    df = df.append(result, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-04T14:02:40.259809Z",
     "iopub.status.busy": "2022-03-04T14:02:40.259497Z",
     "iopub.status.idle": "2022-03-04T14:02:41.545293Z",
     "shell.execute_reply": "2022-03-04T14:02:41.54439Z",
     "shell.execute_reply.started": "2022-03-04T14:02:40.259775Z"
    }
   },
   "outputs": [],
   "source": [
    "# read dataset with all tweets:\n",
    "dtype={'text': str, 'id': str, 'tweet_id': str, 'title': str, 'outlet': str, 'twitter_handle': str, 'article_url': str, 'adfontes_url': str, 'bias_score': float, 'reliability_score': float}\n",
    "\n",
    "# note: this scrip was implemented using Kaggle's GPU. The dataset 'all_tweets_final' was loaded into the Kaggle repo and accessed from there\n",
    "all_tweets = pd.read_csv('../input/all-tweets-final/all_tweets_final.csv', dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-04T14:02:41.547176Z",
     "iopub.status.busy": "2022-03-04T14:02:41.546872Z",
     "iopub.status.idle": "2022-03-04T14:02:47.692545Z",
     "shell.execute_reply": "2022-03-04T14:02:47.691554Z",
     "shell.execute_reply.started": "2022-03-04T14:02:41.547145Z"
    }
   },
   "outputs": [],
   "source": [
    "# apply text preprocessing to tweets:\n",
    "all_tweets['text_prepared'] = all_tweets['text'].apply(prepare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-04T14:02:47.694293Z",
     "iopub.status.busy": "2022-03-04T14:02:47.694063Z",
     "iopub.status.idle": "2022-03-04T14:02:47.718591Z",
     "shell.execute_reply": "2022-03-04T14:02:47.717397Z",
     "shell.execute_reply.started": "2022-03-04T14:02:47.694265Z"
    }
   },
   "outputs": [],
   "source": [
    "all_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load XLNet & Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-04T14:03:34.138535Z",
     "iopub.status.busy": "2022-03-04T14:03:34.13756Z",
     "iopub.status.idle": "2022-03-04T14:03:34.145613Z",
     "shell.execute_reply": "2022-03-04T14:03:34.144852Z",
     "shell.execute_reply.started": "2022-03-04T14:03:34.138482Z"
    }
   },
   "outputs": [],
   "source": [
    "# read classifier:\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-04T14:03:37.259015Z",
     "iopub.status.busy": "2022-03-04T14:03:37.258729Z",
     "iopub.status.idle": "2022-03-04T14:04:10.740624Z",
     "shell.execute_reply": "2022-03-04T14:04:10.739301Z",
     "shell.execute_reply.started": "2022-03-04T14:03:37.258983Z"
    }
   },
   "outputs": [],
   "source": [
    "model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels = 2)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-04T14:04:59.119245Z",
     "iopub.status.busy": "2022-03-04T14:04:59.118953Z",
     "iopub.status.idle": "2022-03-04T14:05:04.350306Z",
     "shell.execute_reply": "2022-03-04T14:05:04.349371Z",
     "shell.execute_reply.started": "2022-03-04T14:04:59.119198Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('../input/new-hate-model/xlnet_model_hate.bin'))\n",
    "#model.load_state_dict(torch.load('../input/new-hate-model/xlnet_model_hate.bin', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-04T14:05:06.274057Z",
     "iopub.status.busy": "2022-03-04T14:05:06.273591Z",
     "iopub.status.idle": "2022-03-04T14:05:17.055384Z",
     "shell.execute_reply": "2022-03-04T14:05:17.054267Z",
     "shell.execute_reply.started": "2022-03-04T14:05:06.274021Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-04T14:05:18.041231Z",
     "iopub.status.busy": "2022-03-04T14:05:18.040896Z",
     "iopub.status.idle": "2022-03-04T14:05:18.047106Z",
     "shell.execute_reply": "2022-03-04T14:05:18.04602Z",
     "shell.execute_reply.started": "2022-03-04T14:05:18.041193Z"
    }
   },
   "outputs": [],
   "source": [
    "# define variables\n",
    "MAX_LEN = 512\n",
    "class_names = ['non-hate', 'hate'] # 0=non-hate; 1=hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run for all Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-04T14:20:48.289371Z",
     "iopub.status.busy": "2022-03-04T14:20:48.289042Z",
     "iopub.status.idle": "2022-03-04T14:23:21.61029Z",
     "shell.execute_reply": "2022-03-04T14:23:21.609539Z",
     "shell.execute_reply.started": "2022-03-04T14:20:48.289324Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets = all_tweets['text_prepared'].tolist() # 175807 comments\n",
    "results = pd.DataFrame()\n",
    "\n",
    "for tweet in tweets:\n",
    "    results = results.append(predict_hate(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-04T14:24:40.258762Z",
     "iopub.status.busy": "2022-03-04T14:24:40.257896Z",
     "iopub.status.idle": "2022-03-04T14:24:40.264774Z",
     "shell.execute_reply": "2022-03-04T14:24:40.263723Z",
     "shell.execute_reply.started": "2022-03-04T14:24:40.25871Z"
    }
   },
   "outputs": [],
   "source": [
    "# add tweet id\n",
    "results.insert(loc=0, column=\"id\", value=all_tweets['id'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T19:15:20.312669Z",
     "iopub.status.busy": "2022-01-05T19:15:20.312112Z",
     "iopub.status.idle": "2022-01-05T19:15:20.328909Z",
     "shell.execute_reply": "2022-01-05T19:15:20.327931Z",
     "shell.execute_reply.started": "2022-01-05T19:15:20.312636Z"
    }
   },
   "outputs": [],
   "source": [
    "results.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T19:15:20.33015Z",
     "iopub.status.busy": "2022-01-05T19:15:20.329948Z",
     "iopub.status.idle": "2022-01-05T19:15:20.34763Z",
     "shell.execute_reply": "2022-01-05T19:15:20.346692Z",
     "shell.execute_reply.started": "2022-01-05T19:15:20.330124Z"
    }
   },
   "outputs": [],
   "source": [
    "# note: this scrip was implemented using Kaggle's GPU. The classified hate dataset was saved into the Kaggle repo and downloaded manually\n",
    "results.to_csv('all_tweets_hate.csv', header=True, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
