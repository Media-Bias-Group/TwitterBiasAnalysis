{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eb7e5dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6ec96c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = pd.read_csv('../data/twitter/user_ids.csv') # df with user name and user id of the outlets\n",
    "twitter_handles = user_data['username'].tolist()\n",
    "user_ids = user_data['author_id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374ac885",
   "metadata": {},
   "source": [
    "#### all matched tweets: all tweets found that refer to a rated article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "374a7aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no articles found for BoingBoing\n",
      "no articles found for comicsandsdaily\n",
      "no articles found for EveningTimesCC\n",
      "no articles found for NewYorkSun\n"
     ]
    }
   ],
   "source": [
    "# create df with empty columns\n",
    "matched_tweets_all = pd.DataFrame(columns=[])\n",
    "\n",
    "# read all files and add to all_outlets\n",
    "dtype={'text': str, 'author_id': str, 'conversation_id': str, 'id': str, 'entities': str, 'attachments': str, 'referenced_tweets': str, 'withheld': str}\n",
    "parse_dates=['created_at']\n",
    "\n",
    "for handle in twitter_handles:\n",
    "    try:\n",
    "        matched_tweets_all = matched_tweets_all.append(pd.read_csv(f'../data/twitter/article_tweets/{handle}.csv', dtype=dtype, parse_dates=parse_dates)).reset_index(drop=True)\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f'no articles found for {handle}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3a48ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv: \n",
    "#matched_tweets_all.to_csv('data/matched_tweets_all.csv', index=None, header=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c941149",
   "metadata": {},
   "source": [
    "#### all relevant tweets: tweets that have at least 1 comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "eb8bb55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tweets that have at least one comment: 3957\n"
     ]
    }
   ],
   "source": [
    "# read file with relevant tweets:\n",
    "dtype={'text': str, 'author_id': str, 'conversation_id': str, 'id': str, 'entities': str, 'attachments': str, 'referenced_tweets': str, 'withheld': str}\n",
    "parse_dates=['created_at']\n",
    "\n",
    "relevant_tweets_all = pd.read_csv('../data/twitter/relevant_tweets.csv', dtype=dtype, parse_dates=parse_dates)\n",
    "\n",
    "relevant_tweets_ids = relevant_tweets_all['id'].tolist()\n",
    "print(f'number of tweets that have at least one comment: {len(relevant_tweets_ids)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9e2f8e",
   "metadata": {},
   "source": [
    "#### all comments: all comments to all relevant tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "de17f2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all comments & collapse in one df:\n",
    "# create df with empty columns\n",
    "comments_all = pd.DataFrame(columns=[])\n",
    "\n",
    "# read all files and add to all_outlets\n",
    "dtype={'text': str, 'author_id': str, 'conversation_id': str, 'id': str, 'entities': str, 'attachments': str, 'referenced_tweets': str, 'withheld': str}\n",
    "parse_dates=['created_at']\n",
    "\n",
    "for tweet_id in relevant_tweets_ids:\n",
    "    try:\n",
    "        comments_all = comments_all.append(pd.read_csv(f'..data/twitter/comment_collection/{tweet_id}_comments.csv', dtype=dtype, parse_dates=parse_dates)).reset_index(drop=True)\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ca91615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv: \n",
    "#comments_all.to_csv('../data/twitter/comments_all.csv', index=None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12590e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad3f7e14",
   "metadata": {},
   "source": [
    "#### all retweets: all retweets to the relevant tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c68dce5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read all retweets & collapse in one df:\n",
    "# remove rows from matched_tweets_all for which no match was found >> for these tweets retweets were searched\n",
    "matched_tweets = matched_tweets_all.dropna(subset=['id'])\n",
    "matched_tweets_ids = matched_tweets['id'].tolist()\n",
    "\n",
    "# create df with empty columns\n",
    "retweets_all = pd.DataFrame(columns=[])\n",
    "\n",
    "# read all files and add to all_outlets\n",
    "dtype={'text': str, 'author_id': str, 'conversation_id': str, 'id': str, 'referenced_tweets': str}\n",
    "parse_dates=['created_at']\n",
    "\n",
    "for tweet_id in matched_tweets_ids:\n",
    "    try:\n",
    "        retweets_all = retweets_all.append(pd.read_csv(f'../data/twitter/retweet_collection/{tweet_id}_retweet.csv', dtype=dtype, parse_dates=parse_dates)).reset_index(drop=True)\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "205faea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only entries where type = quoted; if type = retweet it is a retweet of the quoted retweet; I'm not interested in simple retweets\n",
    "def replace_brackets(text):\n",
    "    text = re.sub(r'^\\[|\\]$', '', text)\n",
    "    return text\n",
    "\n",
    "def split_string(text):\n",
    "    text = re.split(\"(?<=\\}),\\s\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b374e6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows that have missing values at 'referenced_tweets' (can't  be assigned to 'original' tweet w/o that field)\n",
    "quoted_retweets_all = retweets_all.dropna(subset=['referenced_tweets']).reset_index(drop=True)\n",
    "\n",
    "quoted_retweets_all['referenced_tweets'] = quoted_retweets_all['referenced_tweets'].astype(str) # cast column as type string\n",
    "quoted_retweets_all['referenced_tweets'] = quoted_retweets_all['referenced_tweets'].apply(replace_brackets) # remove squared brackets at beginning & end\n",
    "quoted_retweets_all['referenced_tweets'] = quoted_retweets_all['referenced_tweets'].apply(split_string) # split spring in list of 1 or 2 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8df14b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract column 'referenced_tweets' as a list:\n",
    "referenced_tweets = quoted_retweets_all['referenced_tweets'].tolist()\n",
    "\n",
    "# collect types (quoted or retweet) in new list:\n",
    "types = []\n",
    "for i in range (0, len(referenced_tweets)):\n",
    "    types.append(referenced_tweets[i][0])\n",
    "\n",
    "# convert entries of list to dictionaries:\n",
    "for i in range (0, len(types)):\n",
    "    types[i] = ast.literal_eval(types[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "03e58d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list types to dataframe types:\n",
    "types_df = pd.DataFrame(data=types)\n",
    "types_df = types_df.rename(columns={'id': 'tweet_id'}) # rename column (from 'id' to 'tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ce410eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add type columns to df: \n",
    "quoted_retweets_all = quoted_retweets_all.join(types_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "89cb9f6d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# keep only those of type 'quoted'\n",
    "quoted_retweets_all = quoted_retweets_all[quoted['type'] == 'quoted']\n",
    "\n",
    "# save to csv: \n",
    "#quoted_retweets_all.to_csv('../data/twitter/quoted_retweets_all.csv', header=True, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b3ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e09530a9",
   "metadata": {},
   "source": [
    "### Combine all collected tweets into one DF:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4f2415",
   "metadata": {},
   "source": [
    "#### 1. matched_tweets_all: contains all rated articles and (if exists) the corresponding tweet(s)\n",
    "#### 2. comments_all: contains all the comments belonging to the matched tweets\n",
    "#### 3. retweets_all: contains all the quoted retweets belonging to the matched tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "91c8eb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>bias_score</th>\n",
       "      <th>reliability_score</th>\n",
       "      <th>article_url</th>\n",
       "      <th>adfontes_url</th>\n",
       "      <th>outlet</th>\n",
       "      <th>twitter_handle</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID Delta variant puts men, people of color ...</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>48.00</td>\n",
       "      <td>https://19thnews.org/2021/07/the-covid-delta-v...</td>\n",
       "      <td>https://adfontesmedia.com/19th-news-bias-and-r...</td>\n",
       "      <td>19th News</td>\n",
       "      <td>19thnews</td>\n",
       "      <td>1411877241647206401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Two states have killed the ‘tampon tax,' but a...</td>\n",
       "      <td>-9.33</td>\n",
       "      <td>46.67</td>\n",
       "      <td>https://19thnews.org/2021/07/two-states-have-k...</td>\n",
       "      <td>https://adfontesmedia.com/19th-news-bias-and-r...</td>\n",
       "      <td>19th News</td>\n",
       "      <td>19thnews</td>\n",
       "      <td>1410728425459896324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Women in the Biden White House earn 99 cents f...</td>\n",
       "      <td>-11.00</td>\n",
       "      <td>46.67</td>\n",
       "      <td>https://19thnews.org/2021/07/women-in-the-bide...</td>\n",
       "      <td>https://adfontesmedia.com/19th-news-bias-and-r...</td>\n",
       "      <td>19th News</td>\n",
       "      <td>19thnews</td>\n",
       "      <td>1410951027017256965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Women in the Biden White House earn 99 cents f...</td>\n",
       "      <td>-11.00</td>\n",
       "      <td>46.67</td>\n",
       "      <td>https://19thnews.org/2021/07/women-in-the-bide...</td>\n",
       "      <td>https://adfontesmedia.com/19th-news-bias-and-r...</td>\n",
       "      <td>19th News</td>\n",
       "      <td>19thnews</td>\n",
       "      <td>1410713592425598980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kagan warns Supreme Court has weakened voting ...</td>\n",
       "      <td>-12.00</td>\n",
       "      <td>45.67</td>\n",
       "      <td>https://19thnews.org/2021/07/kagan-dissent-brn...</td>\n",
       "      <td>https://adfontesmedia.com/19th-news-bias-and-r...</td>\n",
       "      <td>19th News</td>\n",
       "      <td>19thnews</td>\n",
       "      <td>1410680098039074817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9856</th>\n",
       "      <td>The Cowboy State Is Hurting As Low Oil Prices ...</td>\n",
       "      <td>6.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>https://www.zerohedge.com/energy/cowboy-state-...</td>\n",
       "      <td>https://adfontesmedia.com/zerohedge-bias-and-r...</td>\n",
       "      <td>ZeroHedge</td>\n",
       "      <td>zerohedge</td>\n",
       "      <td>1272588789756633098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9857</th>\n",
       "      <td>Morgan Stanley Turns Even More Bullish: Hikes ...</td>\n",
       "      <td>8.33</td>\n",
       "      <td>41.00</td>\n",
       "      <td>https://www.zerohedge.com/markets/morgan-stanl...</td>\n",
       "      <td>https://adfontesmedia.com/zerohedge-bias-and-r...</td>\n",
       "      <td>ZeroHedge</td>\n",
       "      <td>zerohedge</td>\n",
       "      <td>1272593722992140290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9858</th>\n",
       "      <td>The Pandemic Moonshot: Printing Money Until Th...</td>\n",
       "      <td>12.50</td>\n",
       "      <td>36.00</td>\n",
       "      <td>https://www.zerohedge.com/markets/pandemic-moo...</td>\n",
       "      <td>https://adfontesmedia.com/zerohedge-bias-and-r...</td>\n",
       "      <td>ZeroHedge</td>\n",
       "      <td>zerohedge</td>\n",
       "      <td>1272598504523755521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9859</th>\n",
       "      <td>Don't Get Distracted by Dividends, Focus on Value</td>\n",
       "      <td>0.67</td>\n",
       "      <td>37.00</td>\n",
       "      <td>https://www.zerohedge.com/news/2021-04-30/dont...</td>\n",
       "      <td>https://adfontesmedia.com/zerohedge-bias-and-r...</td>\n",
       "      <td>ZeroHedge</td>\n",
       "      <td>zerohedge</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9860</th>\n",
       "      <td>What Next for Markets as Storm Clouds Gather O...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>https://www.zerohedge.com/news/2021-01-14/what...</td>\n",
       "      <td>https://adfontesmedia.com/zerohedge-bias-and-r...</td>\n",
       "      <td>ZeroHedge</td>\n",
       "      <td>zerohedge</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9861 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  bias_score  \\\n",
       "0     COVID Delta variant puts men, people of color ...       -1.00   \n",
       "1     Two states have killed the ‘tampon tax,' but a...       -9.33   \n",
       "2     Women in the Biden White House earn 99 cents f...      -11.00   \n",
       "3     Women in the Biden White House earn 99 cents f...      -11.00   \n",
       "4     Kagan warns Supreme Court has weakened voting ...      -12.00   \n",
       "...                                                 ...         ...   \n",
       "9856  The Cowboy State Is Hurting As Low Oil Prices ...        6.00   \n",
       "9857  Morgan Stanley Turns Even More Bullish: Hikes ...        8.33   \n",
       "9858  The Pandemic Moonshot: Printing Money Until Th...       12.50   \n",
       "9859  Don't Get Distracted by Dividends, Focus on Value        0.67   \n",
       "9860  What Next for Markets as Storm Clouds Gather O...        9.00   \n",
       "\n",
       "      reliability_score                                        article_url  \\\n",
       "0                 48.00  https://19thnews.org/2021/07/the-covid-delta-v...   \n",
       "1                 46.67  https://19thnews.org/2021/07/two-states-have-k...   \n",
       "2                 46.67  https://19thnews.org/2021/07/women-in-the-bide...   \n",
       "3                 46.67  https://19thnews.org/2021/07/women-in-the-bide...   \n",
       "4                 45.67  https://19thnews.org/2021/07/kagan-dissent-brn...   \n",
       "...                 ...                                                ...   \n",
       "9856              39.00  https://www.zerohedge.com/energy/cowboy-state-...   \n",
       "9857              41.00  https://www.zerohedge.com/markets/morgan-stanl...   \n",
       "9858              36.00  https://www.zerohedge.com/markets/pandemic-moo...   \n",
       "9859              37.00  https://www.zerohedge.com/news/2021-04-30/dont...   \n",
       "9860              39.00  https://www.zerohedge.com/news/2021-01-14/what...   \n",
       "\n",
       "                                           adfontes_url     outlet  \\\n",
       "0     https://adfontesmedia.com/19th-news-bias-and-r...  19th News   \n",
       "1     https://adfontesmedia.com/19th-news-bias-and-r...  19th News   \n",
       "2     https://adfontesmedia.com/19th-news-bias-and-r...  19th News   \n",
       "3     https://adfontesmedia.com/19th-news-bias-and-r...  19th News   \n",
       "4     https://adfontesmedia.com/19th-news-bias-and-r...  19th News   \n",
       "...                                                 ...        ...   \n",
       "9856  https://adfontesmedia.com/zerohedge-bias-and-r...  ZeroHedge   \n",
       "9857  https://adfontesmedia.com/zerohedge-bias-and-r...  ZeroHedge   \n",
       "9858  https://adfontesmedia.com/zerohedge-bias-and-r...  ZeroHedge   \n",
       "9859  https://adfontesmedia.com/zerohedge-bias-and-r...  ZeroHedge   \n",
       "9860  https://adfontesmedia.com/zerohedge-bias-and-r...  ZeroHedge   \n",
       "\n",
       "     twitter_handle                   id  \n",
       "0          19thnews  1411877241647206401  \n",
       "1          19thnews  1410728425459896324  \n",
       "2          19thnews  1410951027017256965  \n",
       "3          19thnews  1410713592425598980  \n",
       "4          19thnews  1410680098039074817  \n",
       "...             ...                  ...  \n",
       "9856      zerohedge  1272588789756633098  \n",
       "9857      zerohedge  1272593722992140290  \n",
       "9858      zerohedge  1272598504523755521  \n",
       "9859      zerohedge                  NaN  \n",
       "9860      zerohedge                  NaN  \n",
       "\n",
       "[9861 rows x 8 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare matched_tweets_all for join: \n",
    "drop = ['text', 'title_manipulated', 'article_urls_manipulated', 'date', 'expanded_urls', 'expanded_urls_manipulated', 'unwound_urls', 'unwound_urls_manipulated', 'entities', 'created_at', 'conversation_id', 'text_manipulated', 'author_id', 'referenced_tweets', 'attachments', 'withheld']\n",
    "matched_tweets_all = matched_tweets_all.drop(columns=drop)\n",
    "matched_tweets_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "828b9931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122743\n"
     ]
    }
   ],
   "source": [
    "# prepare comments_all for join:\n",
    "comments_all.dtypes\n",
    "drop = ['author_id', 'in_reply_to_user_id', 'created_at', 'referenced_tweets', 'withheld']\n",
    "comments_all = comments_all.drop(columns=drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "27384d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122740\n"
     ]
    }
   ],
   "source": [
    "comments_all = comments_all.drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0a6fe505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53140\n"
     ]
    }
   ],
   "source": [
    "# prepare retweets_all for join:\n",
    "drop = ['created_at', 'referenced_tweets', 'author_id', 'conversation_id', 'in_reply_to_user_id', 'withheld', 'type']\n",
    "quoted_retweets_all = quoted_retweets_all.drop(columns=drop) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9b34bc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53138\n"
     ]
    }
   ],
   "source": [
    "quoted_retweets_all = quoted_retweets_all.drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9436ddee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join matched_tweets_all with comments_all:\n",
    "join_comments = matched_tweets_all.merge(comments_all, how='inner', left_on='id', right_on='conversation_id', suffixes=('_left', '_right'))\n",
    "join_comments = join_comments.rename(columns={'conversation_id': 'tweet_id', 'id_right': 'id'})\n",
    "join_comments = join_comments.drop(columns=['id_left'])\n",
    "\n",
    "# join matched_tweets_all with quoted:\n",
    "join_retweets = matched_tweets_all.merge(quoted_retweets_all, how='inner', left_on='id', right_on='tweet_id', suffixes=('_left', '_right'))\n",
    "join_retweets = join_retweets.rename(columns={'id_right': 'id'})\n",
    "join_retweets = join_retweets.drop(columns=['id_left'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9970dd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate both dataframes: \n",
    "all_tweets = pd.concat([join_comments, join_retweets], axis=0)\n",
    "\n",
    "# reorder columns:\n",
    "all_tweets = all_tweets[['id', 'text', 'tweet_id', 'title', 'outlet', 'twitter_handle', 'article_url', 'adfontes_url', 'bias_score', 'reliability_score']]\n",
    "\n",
    "# sort df: \n",
    "all_tweets = all_tweets.sort_values(by='outlet', key=lambda col: col.str.lower()).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "634ab7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = all_tweets.drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3407fdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv:\n",
    "#all_tweets.to_csv('../data/twitter/all_tweets_final.csv', header=True, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d03dc64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
